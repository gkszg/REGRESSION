{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "import random\n",
    "from keras import optimizers\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, Convolution2D, MaxPooling2D, Conv1D, MaxPooling1D\n",
    "from keras.layers.convolutional import ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from keras.initializers import glorot_uniform\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "SEED_VAL = 128\n",
    "os.environ['SEED_NN'] = str(SEED_VAL)\n",
    "random.seed(SEED_VAL)\n",
    "np.random.seed(SEED_VAL)\n",
    "tf.set_random_seed(SEED_VAL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLE = 25\n",
    "TEST_SAMPLE_ID = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 12, 650, 650)\n"
     ]
    }
   ],
   "source": [
    "#Time-samples\n",
    "#for all hdf5 files\n",
    "all_hdf5_data = np.zeros((N_SAMPLE,12,650,650),dtype=np.uint16)\n",
    "\n",
    "\n",
    "for i in range(N_SAMPLE):\n",
    "    data_file = h5py.File(str(i) + '_level2a.h5', 'r')\n",
    "    arr = data_file.get('bands')\n",
    "   \n",
    "    np_arr =  np.array(arr, dtype=np.uint16)\n",
    "    \n",
    "    all_hdf5_data[i] = np_arr\n",
    "    \n",
    "\n",
    "print(all_hdf5_data.shape)\n",
    "\n",
    "#print(all_hdf5_data[9])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n"
     ]
    }
   ],
   "source": [
    "# labels \n",
    "# actually cholorophil-a values for regression\n",
    "import pandas\n",
    "import sys \n",
    "\n",
    "labels_index = np.zeros((N_SAMPLE * 10), dtype=np.float16)\n",
    "\n",
    "labels_name = np.zeros((N_SAMPLE * 10), dtype=np.float16)\n",
    "\n",
    "df = pandas.read_csv('chl_values.csv')\n",
    "    #print(df['Label'])\n",
    "labels_name = df['Chl_Value']\n",
    "#print(type(labels_name))\n",
    "\n",
    "for index in range(len(labels_name)):\n",
    "    #print(labels_name[index])\n",
    "    labels_index[index] = labels_name[index]; \n",
    "    #print(index, labels_index[index])\n",
    "\n",
    "\n",
    "print(len(labels_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coordinate\n",
    "s = pandas.read_csv('sensor_pos.csv')\n",
    "#print(df['Label'])\n",
    "S_POS_X = s['X']\n",
    "S_POS_Y = s['Y']\n",
    "#print(S_POS_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number of all samples : ', 250)\n",
      "(' shape: ', (250, 12, 1))\n"
     ]
    }
   ],
   "source": [
    "#patches from hdf5 file\n",
    "#convert to numpy array\n",
    "#n1 = np.array(n1, dtype=np.uint16)\n",
    "n1 = np.zeros((12, 1), dtype= np.uint16)\n",
    "#print (n1.shape)\n",
    "\n",
    "patches_from_sensors = np.zeros((10*N_SAMPLE, 12 , 1), dtype = np.uint16)\n",
    "#print(patches_from_sensors.shape, patches_from_sensors.dtype)\n",
    "#print(patches_from_sensors[0])\n",
    "new_feature_time = np.zeros((1), dtype=np.uint16)\n",
    "# Sensor position (X, Y)\n",
    "# 3X3 Patches \n",
    "# extract patch from data, starts (X-1,Y-1) ends ( X+1, Y+1)\n",
    "# DO NOT FORGET!!!! Meaning of [x:y] is that the new array includes values at the X pos., but not at the Y pos.\n",
    "\n",
    "# Sensor positions\n",
    "#X = 10\n",
    "#Y = 11\n",
    "STEPS = 1\n",
    "\n",
    "#patch = n1[:, X - STEPS: X + STEPS + 1, Y - STEPS: Y + STEPS + 1]\n",
    "#print(patch.shape, patch)\n",
    "\n",
    "#patches_from_sensors[0] = patch\n",
    "#print(patches_from_sensors[0])\n",
    "total = 0\n",
    "\n",
    "\n",
    "    #n1 = pca_hdf5_data[i_sample] # After PCA data\n",
    "    #n1 = ch0_hdf5_data[i_sample] # 1 channel data\n",
    "    #print(i_sample,\"Sample : \", n1.shape) \n",
    "    #extract 10 (# stations) patches for one sample(for one hdf5 file)\n",
    "for i_s in range(len(S_POS_X)):\n",
    "        X = S_POS_X[i_s]\n",
    "        Y = S_POS_Y[i_s]\n",
    "        for i_sample in range(N_SAMPLE):\n",
    "            n1 = all_hdf5_data[i_sample] #original data\n",
    "        # print(\"X - Y:\" , X , Y )\n",
    "        # Patch Shapes : [C,W,H]\n",
    "        #patch = n1[:, X - STEPS: X + STEPS + 1, Y - STEPS: Y + STEPS + 1] #for patch\n",
    "        #print(i_s,\"s: \", patch.shape)\n",
    "        #for a pixel\n",
    "        # If you would like to use more than one channel\n",
    "        # You should change like patch = n1[ :, X: X+ 1, Y: Y + 1] \n",
    "            patch = n1[:, X: X+ 1, Y: Y + 1] \n",
    "        \n",
    "        #print(patch)\n",
    "                \n",
    "        #patch = np.reshape(patch,(patch.shape[0],1))\n",
    "        #patch = np.append(patch, new_feature_time) #for time\n",
    "        #print(\"Patch \"  ,patch.shape)\n",
    "        #patch[12] = i_s\n",
    "            patch = np.reshape(patch,(patch.shape[0],1))\n",
    "        #patnp.append([[1, 2, 3], [4, 5, 6]], [[7, 8, 9]], axis=0)\n",
    "            patches_from_sensors[i_sample + (25 * i_s)] = patch\n",
    "        \n",
    "    \n",
    "print(\"Number of all samples : \",len(patches_from_sensors))\n",
    "print(\" shape: \",patches_from_sensors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def write_txt(data,label, file_n):\n",
    "    with open(file_n, 'a') as f1:\n",
    "        for index in range(data.shape[0]):\n",
    "            for index_i in range(12):\n",
    "               #f1.write(data[index][index_i])\n",
    "                f1.write('{: }'.format(data[index][index_i]))\n",
    "                f1.write(',')\n",
    "                \n",
    "            f1.write('{: }'.format(label[index]))\n",
    "           \n",
    "            f1.write('\\n')\n",
    "\n",
    "    f1.close()\n",
    "    \n",
    "    \n",
    "import os\n",
    "def write_txt_label(data, file_n):\n",
    "    with open(file_n, 'a') as f1:\n",
    "        for index in range(data.shape[0]):\n",
    "            f1.write('{: }'.format(data[index]))\n",
    "            f1.write(' ')\n",
    "            \n",
    "            f1.write('\\n')\n",
    "\n",
    "    f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "train_start_pos = 0*26\n",
    "train_end_pos = 8*26\n",
    "test_end_pos = 10*26\n",
    "\n",
    "i = 9\n",
    "X_train = np.vstack((patches_from_sensors[0*26:i*26], patches_from_sensors[(i+1)*26:10*26,:,:]) )\n",
    "\n",
    "y_train = np.append(labels_index[0*26:i*26], labels_index[(i+1)*26:10*26] )\n",
    "\n",
    "X_train = np.reshape(X_train,  (X_train.shape[0], 12))\n",
    "#y_train = np.reshape(y_train, (y_train.shape[0], 1))\n",
    "\n",
    "\n",
    "print(\"X_train\", X_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "\n",
    "X_test = patches_from_sensors[i*26:(i+1)*26,:,:]\n",
    "#X_test = np.append(X_test, patches_from_sensors[9:10,:,:])\n",
    "y_test =labels_index[i*26:(i+1)*26]\n",
    "\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 12))\n",
    "#y_test = np.reshape(y_test, (y_test.shape[0], 1))\n",
    "\n",
    "print(\"X_test\", X_test.shape)\n",
    "print(\"y_test\", y_test)\n",
    "\n",
    "\n",
    "write_txt(X_train, y_train, 'train_' + str(i) + '.txt')\n",
    "\n",
    "write_txt(X_test, y_test , 'test_' + str(i) + '.txt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------RF REG---------------------\n",
      "---------------TEST - 0--------------------\n",
      "('Correlation Coef.: ', 0.3524053014570755)\n",
      "Mean squared error: 590.81\n",
      "Coefficient of determination: 0.12\n",
      "Mean absolute error: 20.56\n",
      "----------------RF REG---------------------\n",
      "---------------TEST - 1--------------------\n",
      "('Correlation Coef.: ', 0.7577057964813403)\n",
      "Mean squared error: 426.29\n",
      "Coefficient of determination: 0.30\n",
      "Mean absolute error: 15.31\n",
      "----------------RF REG---------------------\n",
      "---------------TEST - 2--------------------\n",
      "('Correlation Coef.: ', 0.8436827197292484)\n",
      "Mean squared error: 285.73\n",
      "Coefficient of determination: 0.51\n",
      "Mean absolute error: 12.45\n",
      "----------------RF REG---------------------\n",
      "---------------TEST - 3--------------------\n",
      "('Correlation Coef.: ', 0.7732962747351083)\n",
      "Mean squared error: 127.13\n",
      "Coefficient of determination: 0.59\n",
      "Mean absolute error: 7.93\n",
      "----------------RF REG---------------------\n",
      "---------------TEST - 4--------------------\n",
      "('Correlation Coef.: ', 0.06998134457955694)\n",
      "Mean squared error: 560.58\n",
      "Coefficient of determination: -0.47\n",
      "Mean absolute error: 17.99\n",
      "----------------RF REG---------------------\n",
      "---------------TEST - 5--------------------\n",
      "('Correlation Coef.: ', 0.6129959622323645)\n",
      "Mean squared error: 183.83\n",
      "Coefficient of determination: 0.05\n",
      "Mean absolute error: 10.78\n",
      "----------------RF REG---------------------\n",
      "---------------TEST - 6--------------------\n",
      "('Correlation Coef.: ', 0.5528215207668076)\n",
      "Mean squared error: 468.11\n",
      "Coefficient of determination: -1.20\n",
      "Mean absolute error: 15.64\n",
      "----------------RF REG---------------------\n",
      "---------------TEST - 7--------------------\n",
      "('Correlation Coef.: ', 0.8340095762813952)\n",
      "Mean squared error: 125.58\n",
      "Coefficient of determination: -0.18\n",
      "Mean absolute error: 8.85\n",
      "----------------RF REG---------------------\n",
      "---------------TEST - 8--------------------\n",
      "('Correlation Coef.: ', 0.8074665092758792)\n",
      "Mean squared error: 109.85\n",
      "Coefficient of determination: 0.62\n",
      "Mean absolute error: 8.16\n",
      "----------------RF REG---------------------\n",
      "---------------TEST - 9--------------------\n",
      "('Correlation Coef.: ', 0.7491368391668434)\n",
      "Mean squared error: 443.76\n",
      "Coefficient of determination: 0.45\n",
      "Mean absolute error: 16.64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(10):\n",
    "    X_train = np.vstack((patches_from_sensors[0*N_SAMPLE:i*N_SAMPLE], patches_from_sensors[(i+1)*N_SAMPLE:10*N_SAMPLE,:,:]) )\n",
    "\n",
    "    y_train = np.append(labels_index[0*N_SAMPLE:i*N_SAMPLE], labels_index[(i+1)*N_SAMPLE:10*N_SAMPLE] )\n",
    "\n",
    "    X_train = np.reshape(X_train,  (X_train.shape[0], 12))\n",
    "    #y_train = np.reshape(y_train, (y_train.shape[0], 1))\n",
    "\n",
    "\n",
    "    #print(\"X_train\", X_train.shape)\n",
    "    #print(\"y_train\", y_train.shape)\n",
    "\n",
    "    X_test = patches_from_sensors[i*N_SAMPLE:(i+1)*N_SAMPLE,:,:]\n",
    "    #X_test = np.append(X_test, patches_from_sensors[9:10,:,:])\n",
    "    y_test =labels_index[i*N_SAMPLE:(i+1)*N_SAMPLE]\n",
    "\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], 12))\n",
    "    #y_test = np.reshape(y_test, (y_test.shape[0], 1))\n",
    "\n",
    "    #print(\"X_test\", X_test.shape)\n",
    "    #print(\"y_test\", y_test)\n",
    "    \n",
    "    \n",
    "    regr = RandomForestRegressor(n_estimators = 100, random_state=42).fit(X_train, y_train)\n",
    "    print(\"----------------RF REG---------------------\")\n",
    "    print(\"---------------TEST - \"  + str(i) +  \"--------------------\")\n",
    "    # Make predictions using the testing set\n",
    "    y_pred = regr.predict(X_test) #for SVR\n",
    "\n",
    "    #print(y_pred)\n",
    "    #print(\"Real Values : \",y_test)\n",
    "    #print(\"Predictions : \", y_pred) \n",
    "    r = np.corrcoef(y_test, y_pred)\n",
    "\n",
    "    # Correlation Coefficients\n",
    "    print('Correlation Coef.: ',r[0, 1] )\n",
    "    # The mean squared error\n",
    "    print('Mean squared error: %.2f'\n",
    "          % mean_squared_error(y_test, y_pred))\n",
    "    # The coefficient of determination: 1 is perfect prediction\n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_test, y_pred))\n",
    "    print('Mean absolute error: %.2f'\n",
    "          % mean_absolute_error(y_test, y_pred))\n",
    " \n",
    "\n",
    "\n",
    "    write_txt(X_train, y_train, 'train_' + str(i) + '.arff')\n",
    "\n",
    "    write_txt(X_test, y_test , 'test_' + str(i) + '.arff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot outputs\n",
    "plt.scatter(X_test[:,0], y_test,  color='black')\n",
    "plt.plot(X_test, y_pred, color='blue', linewidth=3)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SUPPORT VECTOR REG.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# reshape data\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 12))\n",
    "\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 12))\n",
    "\n",
    "\n",
    "# Fit regression model\n",
    "#svr_rbf = svm.SVR(kernel='sigmoid', C=100, gamma=0.1, epsilon=.1).fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_test = np.reshape(y_test, (y_test.shape[0]))\n",
    "\n",
    "# Train the model using the training sets\n",
    "\n",
    "#regr = svm.SVR().fit(X_train, y_train)\n",
    "#regr =  BayesianRidge(compute_score=True).fit(X_train, y_train)\n",
    "#regr = tree.DecisionTreeRegressor().fit(X_train, y_train)\n",
    "regr = RandomForestRegressor(n_estimators = 100, random_state=42).fit(X_train, y_train)\n",
    "print(\"----------------RF REG---------------------\")\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regr.predict(X_test) #for SVR\n",
    "\n",
    "#print(y_pred)\n",
    "print(\"Real Values : \",y_test)\n",
    "print(\"Predictions : \", y_pred) \n",
    "#r = np.corrcoef(y_test, y_pred)\n",
    "\n",
    "# Correlation Coefficients\n",
    "#print('Correlation Coef.: ',r[0, 1] )\n",
    "# The mean squared error\n",
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))\n",
    "print('Mean absolute error: %.2f'\n",
    "      % mean_absolute_error(y_test, y_pred))\n",
    "# Plot outputs\n",
    "plt.scatter(X_test[:,0], y_test,  color='black')\n",
    "plt.plot(X_test, y_pred, color='blue', linewidth=3)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SUPPORT VECTOR REG.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# reshape data\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 13))\n",
    "\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 13))\n",
    "\n",
    "svr_poly = svm.SVR(kernel='poly', C=100, gamma=0.1, degree=3, epsilon=.1,\n",
    "               coef0=1).fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"----------------SVR-POLY---------------------\")\n",
    "# Make predictions using the testing set\n",
    "y_pred = svr_poly.predict(X_test) #for SVR\n",
    "\n",
    "\n",
    "#print(y_pred)\n",
    "print(\"Real Values : \",y_test)\n",
    "print(\"Predictions : \", y_pred) \n",
    "\n",
    "\n",
    "print('Correlation Coef.: %.2f'\n",
    "      % np.corrcoef(y_test, y_pred))\n",
    "# The mean squared error\n",
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))\n",
    "print('Mean absolute error: %.2f'\n",
    "      % mean_absolute_error(y_test, y_pred))\n",
    "# Plot outputs\n",
    "plt.scatter(X_test[:,0], y_test,  color='black')\n",
    "plt.plot(X_test, y_pred, color='blue', linewidth=3)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SUPPORT VECTOR REG.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# reshape data\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 13))\n",
    "\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 13))\n",
    "\n",
    "svr_lin = svm.SVR(kernel='linear', C=100, gamma='auto').fit(X_train, y_train)\n",
    "print(\"----------------SVR-LINEAR---------------------\")\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = svr_lin.predict(X_test) #for SVR\n",
    "\n",
    "\n",
    "\n",
    "#print(y_pred)\n",
    "print(\"Real Values : \",y_test)\n",
    "print(\"Predictions : \", y_pred) \n",
    "\n",
    "# The mean squared error\n",
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))\n",
    "print('Mean absolute error: %.2f'\n",
    "      % mean_absolute_error(y_test, y_pred))\n",
    "# Plot outputs\n",
    "plt.scatter(X_test[:,0], y_test,  color='black')\n",
    "plt.plot(X_test, y_pred, color='blue', linewidth=3)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
